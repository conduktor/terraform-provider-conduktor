---
page_title: "Conduktor : conduktor_console_kafka_subject_v2 "
subcategory: "console/v2"
description: |-
    Resource for managing Kafka subjects definition linked to an existing Kafka schema cluster definition inside Conduktor Console.
    This resource allows you to create, read, update and delete Kafka subjects connections from Conduktor Console.
---

# conduktor_console_kafka_subject_v2

Resource for managing Kafka subjects definition linked to an existing Kafka schema cluster definition inside Conduktor Console.
This resource allows you to create, read, update and delete Kafka subjects connections from Conduktor Console.

## Example Usage

### Minimal Kafka subject
This example creates a simple Kafka subject with minimal configuration.
```terraform
resource "conduktor_console_kafka_subject_v2" "minimal" {
  name    = "minimal.value"
  cluster = "kafka-cluster"
  spec = {
    format = "JSON"
    schema = jsonencode(
      {
        "$id" : "https://mycompany.com/myrecord",
        "$schema" : "https://json-schema.org/draft/2019-09/schema",
        "type" : "object",
        "title" : "MyRecord",
        "description" : "Json schema for MyRecord",
        "properties" : {
          "id" : {
            "type" : "string"
          },
          "name" : {
            "type" : ["string", "null"]
          }
        },
        "required" : ["id"],
        "additionalProperties" : false
      }
    )
  }
}
```

### Kafka subject JSON
This example creates a complex Kafka JSON subject with all available configuration.
```terraform
resource "conduktor_console_kafka_subject_v2" "this" {
  name    = "minimal_subject"
  cluster = "kafka-cluster"
  spec = {
    format = "JSON"
    schema = jsonencode(
      {
        "$id" : "https://mycompany.com/myrecord",
        "$schema" : "https://json-schema.org/draft/2019-09/schema",
        "type" : "object",
        "title" : "MyRecord",
        "description" : "Json schema for MyRecord",
        "properties" : {
          "id" : {
            "type" : "string"
          },
          "name" : {
            "type" : ["string", "null"]
          }
        },
        "required" : ["id"],
        "additionalProperties" : false
      }
    )
  }
}

resource "conduktor_console_kafka_subject_v2" "complex" {
  name    = "complex.value"
  cluster = "kafka-cluster"
  labels = {
    "team"        = "test"
    "environment" = "test"
  }
  spec = {
    format        = "JSON"
    compatibility = "BACKWARD"
    schema = jsonencode(
      {
        "$id" : "https://mycompany.com/myrecord",
        "$schema" : "https://json-schema.org/draft/2019-09/schema",
        "type" : "object",
        "title" : "MyRecord",
        "description" : "Json schema for MyRecord",
        "properties" : {
          "id" : {
            "type" : "string"
          },
          "name" : {
            "type" : ["string", "null"]
          }
        },
        "required" : ["id"],
        "additionalProperties" : false
      }
    )
    references = [
      {
        name    = "example-reference"
        subject = conduktor_console_kafka_subject_v2.this.name
        version = 1
      }
    ]
  }
}
```

### Kafka subject PROTOBUF
This example creates a complex Kafka PROTOBUF subject with all available configuration.
```terraform
resource "conduktor_console_kafka_subject_v2" "protobuf" {
  name    = "protobuf.value"
  cluster = "kafka-cluster"
  labels = {
    "team"        = "test"
    "environment" = "test"
  }
  spec = {
    format        = "PROTOBUF"
    compatibility = "BACKWARD"
    schema = trimspace(<<-EOF
      syntax = "proto3";

      message MyRecord {
        int32 id = 1;
        string createdAt = 2;
        string name = 3;
      }
    EOF
    )
  }
}
```

### Kafka subject AVRO
This example creates a complex Kafka AVRO subject with all available configuration.
```terraform
resource "conduktor_console_kafka_subject_v2" "avro" {
  name    = "avro.value"
  cluster = "kafka-cluster"
  labels = {
    "team"        = "test"
    "environment" = "test"
  }
  spec = {
    format        = "AVRO"
    compatibility = "FORWARD_TRANSITIVE"
    schema = jsonencode(
      {
        "type" : "record",
        "name" : "MyRecord",
        "namespace" : "com.mycompany",
        "fields" : [
          {
            "name" : "id",
            "type" : "long"
          }
        ]
      }
    )
  }
}
```

Note - we used inline schemas in these examples. However it is our suggestion that in production you keep the schemas in individual files.

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `cluster` (String) Kafka cluster name linked with Kafka subject. Must already exist in Conduktor Console. Any change will require the Subject to be destroyed and re-created
- `name` (String) Kafka subject name, must be unique, acts as an ID for import
- `spec` (Attributes) Kafka subject spec (see [below for nested schema](#nestedatt--spec))

### Optional

- `labels` (Map of String) Kafka connect server labels

### Read-Only

- `managed_labels` (Map of String) Read-only Conduktor managed labels labels for the topic resource. Used in Conduktor's topic catalog and UI

<a id="nestedatt--spec"></a>
### Nested Schema for `spec`

Required:

- `format` (String) Kafka subject format (AVRO, JSON, PROTOBUF)
- `schema` (String) Kafka subject schema

Optional:

- `compatibility` (String) Kafka subject compatibility (BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE)
- `references` (Attributes Set) Array of objects (SchemaReference) (see [below for nested schema](#nestedatt--spec--references))

Read-Only:

- `id` (Number) Kafka subject ID
- `version` (Number) Kafka subject version

<a id="nestedatt--spec--references"></a>
### Nested Schema for `spec.references`

Required:

- `name` (String) name required string
- `subject` (String) subject required string
- `version` (Number) version required integer





## Import

In order to import a Kafka subject, you need to know the Kafka cluster ID and the Kafka subject name.

The import ID is constructed as follows: `< cluster_id >/< subject_name >`.

For example, using an [`import` block](https://developer.hashicorp.com/terraform/language/import) :
```terraform
import {
  to = conduktor_console_kafka_subject_v2.example
  id = "my-cluster/import-subject"
}
```

Using the `terraform import` command:
```shell
terraform import conduktor_console_kafka_subject_v2.example mini-cluster/import-subject
```

## Known Issues and Limitations

### External References in JSON Schema
- **Use full URL `$id` for external references**: When using external `$ref` in JSON schema, always use the full URL `$id` to reference external schemas. If you use relative paths, Schema Registry will resolve them differently and modify the schema content, causing Terraform state comparison failures.
- **Reference version updates require recreation**: Due to API limitations, updating the `version` field in `spec.references[]` will not properly update the schema. As a workaround, you must destroy and recreate the subject resource to update reference versions.